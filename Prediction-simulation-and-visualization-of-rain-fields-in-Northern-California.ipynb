{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from scipy import spatial\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linspace\n",
    "import simplekml\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the prediction, simulation and visualization class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PierrePredictor:\n",
    "    # Gaussian Process Regression\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        # The dimension of the data\n",
    "        self.n_dim = len(data)\n",
    "        \n",
    "    def K(self, X, Z, h):\n",
    "        # The Covariance Matrix\n",
    "        d = spatial.distance_matrix(X,Z)\n",
    "        K = np.exp(-(d**2) / (2*h*h)) \n",
    "        return K\n",
    "    \n",
    "    def mean_f(self,h,sigma,X,Z,Y):\n",
    "        # The predictive mean m(f)\n",
    "        K_X_X = self.K(X,X,h)\n",
    "        K_test_X = self.K(Z,X,h)\n",
    "        Id = np.identity(X.shape[0])\n",
    "        S=np.linalg.inv(K_X_X+sigma*Id)\n",
    "        m=np.dot(K_test_X,np.dot(S,Y))\n",
    "        return m\n",
    "\n",
    "    def cov_f(self,h,sigma,X,Z):\n",
    "        # The predictive cov(f)\n",
    "        K_test = self.K(Z,Z,h)\n",
    "        K_test_X = self.K(Z,X,h)\n",
    "        K_X_test = self.K(X,Z,h)\n",
    "        K_X_X = self.K(X,X,h)\n",
    "        Id = np.identity(X.shape[0])\n",
    "        S=np.linalg.inv(K_X_X+sigma*Id)\n",
    "        cov_f = K_test-np.dot(K_test_X,np.dot(S,K_X_test))\n",
    "        return cov_f\n",
    "        \n",
    "    def L(self,h,sigma,X,Z):\n",
    "        # The Cholesky decomposition of the predictive cov(f)\n",
    "        cov_f = self.cov_f(h,sigma,X,Z)\n",
    "        L = np.linalg.cholesky(cov_f + 0.001*np.eye(cov_f.shape[0]))\n",
    "        return L\n",
    "    \n",
    "    def f_sim(self,h,sigma,X,Z,Y):\n",
    "        # The conditional stochastic simulations of f\n",
    "        m = self.mean_f(h,sigma,X,Z,Y)\n",
    "        L = self.L(h,sigma,X,Z)\n",
    "        mean_f_u = np.zeros(Z.shape[0])\n",
    "        Id = np.identity(Z.shape[0])\n",
    "        u = np.random.multivariate_normal(mean_f_u,Id)\n",
    "        u.shape=Z.shape[0],1\n",
    "        fsim = m + np.dot(L,u)\n",
    "        return fsim\n",
    "    \n",
    "    def visualization(self,fsim,n_squared_grid,bounding_box):\n",
    "        \n",
    "        # bounding_box = List of the latitude & longitude of the bounding box\n",
    "        # We reshape fsim in a grid of n_squared_grid * n_squared_grid\n",
    "        \n",
    "        fsim_reshaped = np.transpose(np.asarray(np.array_split(fsim,n_squared_grid)))\n",
    "        \n",
    "        # Exportation of the picture in a .png file\n",
    "        \n",
    "        fig = plt.figure(2)\n",
    "\n",
    "        cmap = mpl.colors.LinearSegmentedColormap.from_list('my_colormap',\n",
    "                                                   ['darkblue','blue','lightblue','green','lightgreen','yellow'\n",
    "                                                    ,'orange','red','darkred']\n",
    "                                                    ,256)\n",
    "\n",
    "        img = plt.imshow(fsim_reshaped,interpolation='nearest',cmap = cmap,origin='lower')\n",
    "\n",
    "        fig.savefig(\"Picture of the simulated rainfall.png\",transparent=True,frameon=False,pad_inches=0,bbox_inches='tight')\n",
    "        \n",
    "        # Exportation of the picture in a .kml file, readable by Google Earth\n",
    "        \n",
    "        kml = simplekml.Kml()\n",
    "        ground = kml.newgroundoverlay(name='GroundOverlay')\n",
    "        ground.icon.href = 'Picture of the simulated rainfall.png'\n",
    "        \n",
    "        ground.latlonbox.north = bounding_box[1]\n",
    "        ground.latlonbox.south = bounding_box[0]\n",
    "        ground.latlonbox.east = bounding_box[2]\n",
    "        ground.latlonbox.west = bounding_box[3]\n",
    "        ground.latlonbox.rotation = 0\n",
    "\n",
    "        ground.color = \"aaffffff\"\n",
    "        kml.save(\"Picture of the simulated rainfall.kml\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('trn_data.csv', delimiter=',', skip_header=1)\n",
    "X, Y = data[:,:-1], data[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictor=PierrePredictor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cross - validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the k - fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.n_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "414 / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "X_random, Y_random = data[:,:-1], data[:,-1:]\n",
    "X_folds = np.array_split(X_random, 9)\n",
    "Y_folds = np.array_split(Y_random, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of the RMSE function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "            return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross - Validation on both h & sigma, using fsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738888888889 0.255555555556\n"
     ]
    }
   ],
   "source": [
    "liste_rmse=[]\n",
    "minimum_h=[]\n",
    "minimum_sigma=[]\n",
    "liste_h_sigma=[]\n",
    "\n",
    "for i in range(9):\n",
    "    X_train_cv = list(X_folds)\n",
    "    X_test_cv  = X_train_cv.pop(i)\n",
    "    X_train_cv = np.concatenate(X_train_cv)\n",
    "    \n",
    "    Y_train_cv = list(Y_folds)\n",
    "    Y_test_cv  = Y_train_cv.pop(i)\n",
    "    Y_train_cv = np.concatenate(Y_train_cv)\n",
    "    \n",
    "    for h in np.arange(0.05,3,0.05):\n",
    "        for sigma in np.arange(0.05,1,0.05):\n",
    "          \n",
    "            mean = predictor.mean_f(h,sigma,X_train_cv,X_test_cv,Y_train_cv)\n",
    "            \n",
    "            liste_h_sigma.append([h,sigma])\n",
    "            liste_rmse.append(rmse(mean,Y_test_cv))\n",
    "\n",
    "    every_minimum=liste_h_sigma[liste_rmse.index(min(liste_rmse))]\n",
    "    \n",
    "    minimum_sigma.append(every_minimum[1])\n",
    "    minimum_h.append(every_minimum[0])\n",
    "\n",
    "    liste_rmse=[]\n",
    "    liste_h_sigma=[]\n",
    "    \n",
    "best_h=sum(minimum_h)/float(len(minimum_h))\n",
    "best_sigma = sum(minimum_sigma)/float(len(minimum_sigma))\n",
    "\n",
    "print best_h, best_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I fix h and sigma because their calculation take a very long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_chosen_fixed = 0.738888888889\n",
    "sigma_chosen_fixed = 0.255555555556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation of the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413L, 2L)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.genfromtxt('tst_locations.csv', delimiter=',', skip_header=1)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with m(f) & exportation as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predictive mean #\n",
    "\n",
    "mean = predictor.mean_f(h_chosen_fixed,sigma_chosen_fixed,X,test,Y)\n",
    "\n",
    "# Exportation as a csv file for the kaggle competition #\n",
    "\n",
    "t = open('Predicitve_mean_m(f).csv', 'w')\n",
    "open_file_object = csv.writer(t)\n",
    "\n",
    "open_file_object.writerow(['id','mm'])\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    open_file_object.writerow([i+1,int(mean[i])])\n",
    "\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413L, 1L)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500L, 2L)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = np.genfromtxt('grid.csv', delimiter=',')\n",
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500L, 1L)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsim = predictor.f_sim(h_chosen_fixed,sigma_chosen_fixed,X,grid,Y)\n",
    "fsim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I save fsim in order to use it after, without having to recalculate everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=fsim.tolist()\n",
    "\n",
    "fsim_csv = open('fsim_output.csv', 'w')\n",
    "open_file_object = csv.writer(fsim_csv)\n",
    "\n",
    "for i in range(grid.shape[0]):\n",
    "    open_file_object.writerow(d[i])\n",
    "\n",
    "fsim_csv.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500L,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation of fsim #\n",
    "\n",
    "fsim_2500 = np.genfromtxt('fsim_output.csv')\n",
    "fsim_2500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor.visualization(fsim_2500,50,[38.5,39.3,-119.8,-120.8])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
